\documentclass{scrartcl}% siehe <http://www.komascript.de>
\input{../lectures-tex/configuration}

\begin{document}
    \header{Algorithmen und Berechenbarkeit}{Mitschrift}{Vorlesung 03}

    \section*{Landau-Symbole und Laufzeiten}
    \label{subsec:laufzeiten}

    \begin{itemize}
        \item $\mathcal{O}(n^2)$ Die Menge aller Funktionen, die (asymptotisch)\\
        nicht schneller wachsen als $n^2.\hfill (\leq)$
        \item $o(n^2)$ Die Menge aller Funktionen, die (asymptotisch)\\
        echt langsamer wachsen als $n^2.\hfill (<)$
        \item $\Omega(n^2)$ Die Menge aller Funktionen, die (asymptotisch)\\
        mindestens so schnell wachsen wie $n^2.\hfill (\geq)$
        \item $\omega(n^2)$ Die Menge aller Funktionen, die (asymptotisch)\\
        echt schneller wachsen als $n^2.\hfill (>)$
        \item $\Theta(n^2)$ Die Menge aller Funktionen, die (asymptotisch)\\
        genau so schnell wachsen wie $n^2.\hfill (=)$
    \end{itemize}

    \section*{Einschub: Vergleichsbasiertes Sortieren}
    \label{subsec:vergleichsbasiertessortieren}

    Beim \kursiv{vergleichsbasierten Sortieren} von $n$ Objekten,
    wobei die Elemente nur verglichen werden dürfen,
    liefert jeder Algorithmus eine obere Schranke für $T(n)$ (Laufzeit für $n$ Elemente).
    Zum Beispiel ist die obere Schranke von \fett{Bubblesort} $\in \mathcal{O}(n^2)$
    und die von \fett{Mergesort} $\in \mathcal{O}(n \cdot \log(n))$.

    \begin{satz}
        Es kann bewiesen werden, dass $T(n) \in \Omega(n \cdot \log(n)) \Rightarrow T(n) \in \Theta(n \cdot \log(n))$.
    \end{satz}

    \begin{proof}
        Sei $A$ ein beliebiger Algorithmus zum Sortieren. $A$ vergleicht $e_i$ mit $e_j$.
        Die Vergleiche können exemplarisch als Binärbaum skizziert werden.
        \begin{figure}[htb]
            \centering
            \begin{tikzpicture}[level distance=1.5cm,
            level 1/.style={sibling distance=7cm},
            level 2/.style={sibling distance=4.5cm},
            every node/.style = {shape=rectangle, rounded corners,
            draw, align=center,
            top color=upforestgreen!30, bottom color=upforestgreen!30}]
                \node {Vergleiche $e_1$ mit $e_2$}
                child { node {Vergleiche $e_3$ mit $e_5$}child {node {\dots}}
                child {node {\dots}}
                }
                child { node {Vergleiche $e_4$ mit $e_6$}child {node {\dots}}
                child {node {\dots}}
                }
                ;
            \end{tikzpicture}
        \end{figure}

        Trifft der Algorithmus auf ein Blatt des Binärbaums, so hat der Algorithmus fertig sortiert,
        bzw.\ der Algorithmus hat \kursiv{herausgefunden}, was die Permutation der Eingabe war.
        Es lässt sich nun festhalten

        \begin{enumerate}
            \item Der Baum muss $n!$ Blätter haben.
            \item Die Worst-Case-Laufzeit des Algorithmus $A$ entspricht genau der Tiefe des Baums.
        \end{enumerate}

        Nun lässt sich die minimale Tiefe eines Binärbaums, der $n!$ Blätter hat, berechnen. Sei

        \begin{equation*}
            2^n \approx n! \approx \left({\frac{n}{e}}\right)^{\frac{n}{e}}
        \end{equation*}

        Sei $x$ die minimale Tiefe. Dann gilt

        \begin{align*}
            x &= \log_2\left(\frac{n}{e}\right)^{\frac{n}{e}}\\
            &= n \cdot \log(n)
        \end{align*}

    \end{proof}

    \section*{Randomisierte Algorithmen: Monte-Carlo und Las-Vegas}
    In Vorlesung 01 und 02 wurden zwei verschiedene Arten von randomisierten Algorithmen angeschnitten:
    Las-Vegas- bzw.\ Monte-Carlo-Algorithmen.

    \begin{itemize}
        \item \fett{Las-Vegas:}
        \begin{itemize}
            \item \kursiv{Charakterisierung:} Die Laufzeit hängt vom Zufall ab, die Korrektheit nicht.
            \item \kursiv{Beispiel}: Randomisierter Closest-Pair-Algorithmus
            \item \kursiv{Umwandlung in Monte-Carlo-Algorithmus:}
            Die Umwandlung von Las-Vegas- in Monte-Carlo-Algorithmen ist möglich.
            Sei $A_L$ ein Las-Vegas-Algorithmus.
            Man lässt $A$ eine bestimmte Anzahl an Schritten laufen und bricht dann ab.
            War $A$ bis dahin fertig, so muss das Ergebnis korrekt sein.
            War $A$ bis dahin nicht fertig, dann gibt es auch kein korrektes Ergebnis.

            Sei $f(n)$ die erwartete Laufzeit von $A$. $A$ darf nun für maximal $\alpha \cdot f(n)$
            (mit $\alpha \geq 1$) Schritte laufen.
            Es gilt: $A$ hat immer eine Laufzeit von $< \alpha \cdot f(n)$.
            Die Wahrscheinlichkeit, dass $A$ ein falsches Resultat liefert,
            entspricht genau der Wahrscheinlichkeit, dass $A$ länger als $\alpha \cdot f(n)$ Zeit benötigt.
        \end{itemize}
        \item \fett{Monte-Carlo:}
        \begin{itemize}
            \item \kursiv{Charakterisierung:} Die Laufzeit hängt nicht vom Zufall ab, die Korrektheit schon.
            \item \kursiv{Beispiel}: Kargers Min-Cut-Algorithmus
            \item \kursiv{Umwandlung in Las-Vegas-Algorithmus:}
            Die Umwandlung ist nicht für alle Monte-Carlo-Algorithmen können ohne Weiteres möglich.
            Für manche Probleme ist die Verifikation des Ergebnisses einfacher als die Berechnung:
            \begin{itemize}
                \item Sortieren: $\mathcal{O}(n \cdot \log(n))$ vs.\ $O(n)$
                \item Kürzeste Wege: $\mathcal{O}(n \cdot \log(n+m))$ vs.\ $O(m)$
            \end{itemize}
            Das Überführen von Monte-Carlo- in Las-Vegas-Algorithmen ist möglich,
            wenn ein effizienter \textit{Checker} existiert. Sei $B$ ein Monte-Carlo-Algorithmus mit Laufzeit $f(n)$,
            sei $C$ ein Checker mit Laufzeit $f(n)$, die Erfolgswahrscheinlichkeit von $B$ sei $p(n)$.
            \newpage
            Ein Las-Vegas-Algorithmus kann nun auf folgende Weise erzeugt werden:
            \begin{figure}[H]
                \centering
                \begin{minipage}{.55\linewidth}
                    \begin{algorithmic}
                        \STATE{lasse $B$ laufen}
                        \IF {$B.result$ ist korrekt}
                        \RETURN {$B.result$}
                        \ELSE
                        \STATE {starte neu}
                        \ENDIF
                    \end{algorithmic}
                \end{minipage}
            \end{figure}

            Für die erwartete Laufzeit $R_B$ ergibt sich
            \begin{align*}
                R_B &= p(n) \cdot \left( f(n) + g(n) \right) \\
                &\quad + ((1 - p(n)) \cdot p(n) \cdot (f(n) + g(n))) \cdot 2\\
                &\quad + ((1 - p(n))^2 \cdot p(n) \cdot (f(n) + g(n))) \cdot 3 +\ \dots \\\nonumber
                &=(f(n) + g(n)) \cdot p(n) \cdot \sum^{\infty}_{i=1}\left( 1-p(n)\right)^{i}\\
                & < \frac{f(n) + g(n)}{p(n)} \cdot (i+1)
            \end{align*}
        \end{itemize}
    \end{itemize}

    \section*{Anhang}
    \label{sec:anhang}

    \subsubsection*{Markov-Ungleichung}
    Sei $X$ eine nicht negative Zufallsvariable mit $E[X] = \mu$.
    Dann gilt:

    \begin{equation*}
        P(X \geq \alpha \cdot \mu ) \leq \frac{1}{\alpha}
    \end{equation*}

\end{document}