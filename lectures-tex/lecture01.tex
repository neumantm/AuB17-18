\documentclass{scrartcl}% siehe <http://www.komascript.de>
\input{../lectures-tex/configuration}

\tikzset{node black/.style={circle,fill=black!100,draw,minimum size=0.05cm,inner sep=0pt},}
\begin{document}
    \headerline{Algorithmen und Berechenbarkeit}{Vorlesungsmitschrift}{Vorlesung 01}
    \section*{Randomisierte Algorithmen}
    \label{sec:randomisierteAlgorithmen}

    Randomisierte Algorithmen sind Algorithmen,
    welche unter Nutzung einer Zufallsquelle (z.B. Münzwurf, Zufallsgenerator) Probleme lösen.
    In manchen Fällen sind diese Algorithmen einfacher und effizienter
    als die entsprechenden deterministischen Algorithmen.

    Randomisierte Algorithmen werden nach "`dem Verbrauch von Zufall"' bewertet,
    denn Zufall zu erzeugen, ist nicht so ohne Weiteres möglich (Zufall zu "`erzeugen"' ist \textbf{teuer}).
    Im Gegensatz dazu bewertet man "`normale"' Algorithmen nach Platz- und Zeitbedarf.

    Wir haben bisher die folgenden Gattungen kennengelernt:

    \begin{itemize}
        \item \textbf{\textsf{Las-Vegas:}} Die Laufzeit hängt vom Zufall ab, die Korrektheit nicht.
        \item \textbf{\textsf{Monte-Carlo:}} Die Laufzeit hängt nicht vom Zufall ab, die Korrektheit schon.
    \end{itemize}

    \subsection*{Closest Pair (Randomisiert, Las-Vegas)}
    \label{subsec:closestPairrandomisiert,LasVegas}

    Gegeben seien $n$ Punkte im $\mathbb{R}^2$

    \begin{figure}[htb]
        \centering
        \framebox        {
        \begin{tikzpicture}[thick, scale=0.5]
            \node[node black] (n1) at (1,0) {};
            \node[node black] (n2) at (1,1.2) {};
            \node[node black] (n3) at (0,3) {};
            \node[node black] (n4) at (1.5,3) {};
            \node[node black] (n5) at (4.1,4.8) {};
            \node[node black] (n6) at (4,4.3) {};
            \node[node black] (n7) at (7.1,2.4) {};
            \node[node black] (n8) at (6.9,1.3) {};
            \node[node black] (n9) at (7,3,3) {};
            \node[node black] (n10) at (6,2.3) {};
            \node[node black] (n11) at (5,0) {};
            \node[node black] (n11) at (3,2.3) {};
        \end{tikzpicture}

        }

    \end{figure}

    Gegeben ist eine Menge $P$ mit $n$ Punkten im $\mathbb{R}^2$.
    Gesucht sind $p,q \in P$ für die gilt: $|pq| = \text{min}|rs|$ mit $r,s \in P$,
    also das Paar mit dem kleinsten Abstand zueinander.

    \subsubsection*{Naiver Ansatz}
    \label{subsec:naiveransatz}

    \begin{itemize}
        \item Betrachte $P_1$ und berechne Distanzen zu $P_2, P_3, \dots, P_n$
        \item Betrachte $P_2$ und berechne Distanzen zu $P_3, P_4, \dots, P_n$
    \end{itemize}

    Das würde eine Laufzeit von

    \begin{equation*}
        O\left(\sum_{i=1}^{n-1}\right) = O\left( \frac{(n-1) \cdot n}{2} \right) = O(n^2)
    \end{equation*}

    ergeben.
    Ein Prozessor mit 1 GHz Taktfrequenz schafft
    1.000.000.000 Instruktionen pro Sekunde.
    Das führt zu folgender Tabelle:
    \begin{table}[H]
        \centering
        \begin{tabular}{llll}
            \textbf{\textsf{n}} & \textbf{\textsf{Rechnung}} & & \textbf{\textsf{Ergebnis}}\\
            \hline \\ [-2ex]
            $=100       $ & $100^2 \cdot 10^{-9}$       & $=10^{-5}$   & $\SI{10}{\us}$ \\
            $=1000      $ & $1000^2 \cdot 10^{-9}$      & $= 10^{-3}$    & \SI{1}{\ms} \\
            $=10000     $ & $10000^2 \cdot 10^{-9}$     & $= 10$         & \SI{10}{\s} \\
            $=1000000   $ & $1000000^2 \cdot 10^{-9}$   & $= 10^3$       & \SI{10}{\min} \\
            \hline \\
        \end{tabular}
    \end{table}
    $O(n^2)$ ist für das Problem nicht praktikabel.

    \subsubsection*{Randomisierter Algorithmus für CP}
    \label{subsec:randomisierterAlgorithmusfürCP}

    Ein randomisierter Algorithmus mit \textit{erwarteter Laufzeit}
    (Varianten: Glück \& Pech) hat eine Laufzeit von $O(n)$.
    Er wird aus folgendem inkrementellen Ansatz hergeleitet:

    Zuerst wird die Datenmenge $P = \{ P_1, P_2, P_3, \dots, P_n \}$ betrachtet.
    Sei nun $\delta_i$ die CP-Distanz in der Menge $P$.
    Es kommt nun ein weiterer Punkt $P_{i+1}$ hinzu.

    Den neuen geringsten Abstand kann man nun dadurch herausfinden,
    dass man die Abstände vom neuen Punkt zu allen anderen Punkten vergleicht und überprüft,
    ob es einen kleineren Abstand als das bisherige $\delta_i$ gibt.

    Besser wäre jedoch Folgendes: Angenommen, $\delta_i$ ist bestimmt.
    So kann nun ein Gitter erzeugt werden, das eine Maschenweite
    (Breite der Zeilen/Spalten) von genau $\delta_i$ hat.

    \begin{figure}[H]
        \centering
        \begin{table}[H]
            \centering
            \scalebox{0.8}{%
            \begin{tabular}{l|l|l|l|l|l|l}
                & & & & $\cdot$ & &  \\ \hline
                & \cellcolor{yellow!50}&\cellcolor{yellow!50} &\cellcolor{yellow!50}$\cdot$ & & $\cdot$ &  \\ \hline
                &\cellcolor{yellow!50} & \cellcolor{orange!75}$\cdot$ &\cellcolor{yellow!50} & & $\cdot$ &  \\ \hline
                & \cellcolor{yellow!50}$\cdot$ &\cellcolor{yellow!50} &\cellcolor{yellow!50} & & &  \\ \hline
                & $\cdot$ & & & & &  \\ \hline
                & & & $\cdot$ & & &
            \end{tabular}
            }
        \end{table}
    \end{figure}

    Das Einfügen folgt einem einfachen Ablauf

    \begin{enumerate}
        \item Lokalisiere $P_{i+1}$ im Gitter (orange)
        \item Inspiziere alle Punkte im Feld von $P_{i+1}$ sowie alle Felder um $P_{i+1}$ herum (gelb)
        \begin{enumerate}
            \item $\delta_{i+1} = \delta_i \rightarrow$ Nichts mehr tun $\rightarrow O(1)$
            \item $\delta_{i+1} < \delta_i \rightarrow$ Baue Gitter mit neuer Maschenweite
            $\delta_{i+1}$ $\rightarrow O(n^2)$ im schlimmsten Fall
        \end{enumerate}
    \end{enumerate}

    Da es auch Fälle geben kann, in denen $P_{i+1}$ immer einen kleineres $\delta$ hat als davor
    (Liste nach größtem Abstand geordnet), empfiehlt es sich, die Punkte immer in zufälliger Reihenfolge "`einzufügen"'.
    So bleibt eine Wahrscheinlichkeit von $\frac{2}{i+1}$ dafür, dass der nächste Punkt ein CP-Punkt ist.

    Die erwarteten Kosten des Einfügens sind

    \begin{equation*}
        \begin{align*}
            & \leq \underbrace{\frac{2}{i+1} \cdot O(n)}_{\text{schlechter Fall}} + \underbrace{O(1)}_{\substack{\text{guter} \\ \text{Fall}}}\\\nonumber
            & = O(1) + O(1) \\\nonumber
            & = O(1)
        \end{align*}
    \end{equation*}

    \newpage
    Damit lässt sich der Erwartungswert berechnen zu

    \begin{equation*}
        \begin{align*}
            E\left[ \sum^{n}_{i=1}(\text{Kosten für Einfügen von }P_i)\right] &= \sum^{n}_{i=1}E[\text{Kosten für Einfügen von }P_i] \\\nonumber
            &= \sum^{n}_{i=1}O(1)\\\nonumber
            & = O(n)
        \end{align*}
    \end{equation*}

    \newproof{Die Wahrscheinlichkeit, beim Einfügen von $P_{i+1}$ das Gitter neu aufbauen zu müssen, ist $< \frac{2}{i+1}$. }
    {
    Das Gitter muss genau dann neu aufgebaut werden, wenn $P_{i+1}$
    einer der beiden Punkte ist, welche das CP in der Menge der ersten $i+1$ Punkte bestimmen.
    Jeder der ersten $i+1$ Punkte ist mit gleicher Wahrscheinlichkeit der $P_{i+1}$.

    Falls CP eindeutig:
    \begin{equation*}
        \rightarrow \text{Pr}(\text{Gitter muss neu aufgebaut werden}) = \frac{2}{i}
    \end{equation*}

    \textbf{\textsf{Wichtig:}} Wenn der Algorithmus länger braucht, hat das nichts mit der Eingabe zu tun.
    Der randomisierte Closest-Pair-Algorithmus berechnet immer ein korrektes Resultat.
    }

    \subsubsection*{Closest Pair mit deterministischem Algorithmus}
    \label{subsec:closestPairmitdeterministischemAlgorithmus}
    Closest Pair kann in $O(n \cdot \log(n))$ berechnet werden.
    Es kann sogar gezeigt werden, dass CP mindestens $\Omega(n \cdot \log(n))$ braucht.

    Deterministisch geht CP vergleichsbasiert nicht besser als $\Omega(n \cdot \log(n))$

    \begin{table}[!ht]
        \centering
        \begin{tabular}{llll}
            \textbf{\textsf{n}} & \textbf{\textsf{Rechnung}} & \textbf{\textsf{Ergebnis}}\\
            \hline \\ [-2ex]
            $=1000000   $ & $10^6 \cdot 6 \cdot  10^{-9}$   & 6 ms \\
            \hline \\
        \end{tabular}
    \end{table}

    \vspace*{0.3cm} \textbf{\textsf{Beweis:}}
        Man weiß, dass Elementuniqueness (gegeben sind $n$ Zahlen, man überprüft, ob eine Zahl doppelt vorkommt)
        $\Omega(n \cdot \log(n))$ braucht.
        Falls CP deterministisch vergleichsbasiert besser als $o(n \cdot \log(n))$
        gelöst werden könnte, so könnte man auch Elementuniqueness in dieser Zeit lösen
        (Zahl $i \rightarrow Punkt \ (i, i) \in \mathbb{R}^2$). Allerdings gilt das nur in einem
        anderem Rechenmodell (Randomisierung und Abrundung).

    \hrulefill

    \section*{Anhang}
    \label{sec:anhang}

    \subsubsection*{Zufallsvariable und Erwartungswert}
    \label{sec:zufallsvariableUndErwartungswert}
    Sei $Y$ eine Zufallsvariable, zum Beispiel \textit{Augenzahl beim Wurf} mit einem normalen und fairen Würfel. \newline
    Der Erwartungswert berechnet sich zu

    \begin{equation*}
        E[X] = \sum \text{Ereignis} \cdot \text{Pr}(\text{Ereignis})
    \end{equation*}

    Für $Y$ also: $\frac{1}{6} \cdot 1 + \frac{1}{6} \cdot 2 + \frac{1}{6} \cdot 3 +
    \frac{1}{6} \cdot 4 + \frac{1}{6} \cdot 5 + \frac{1}{6} \cdot 6 = 3,5$

\end{document}