\documentclass{scrartcl}% siehe <http://www.komascript.de>
\input{../lectures-tex/configuration}

\tikzset{node black/.style={circle,fill=black!100,draw,minimum size=0.05cm,inner sep=0pt},}
\begin{document}
    \header{Algorithmen und Berechenbarkeit}{Mitschrift}{Vorlesung 01}
    \section*{Randomisierte Algorithmen}

    \kursiv{Randomisierte Algorithmen} sind Algorithmen,
    die Probleme unter Einbeziehung einer Zufallsquelle (z.B.\ Münzwurf, Zufallsgenerator) lösen.
    In manchen Fällen sind diese Algorithmen einfacher und effizienter
    als ihre deterministischen Pendants.\\

    Randomisierte Algorithmen werden nach \kursiv{dem Verbrauch von Zufall} bewertet
    (im Gegensatz zu "`normalen"' Algorithmen, die nach Platz- und Zeitbedarf bewertet werden).
    Die "`Generierung"' echten Zufalls ist jedoch \fett{teuer}.

    \section*{Closest-Pair}

    Gegeben sei eine Menge $P$ von Punkten im $\mathbb{R}^2$.
    Finde $p_1,p_2 \in P$ für die $\vert p_{1},p_2 \vert $ (\kursiv{euklidische Distanz}) minimal.

    \begin{figure}[htb]
        \centering
        \framebox        {
        \begin{tikzpicture}[thick, scale=0.7]
            \node[node black] (n1) at (1,0) {};
            \node[node black] (n2) at (1,1.2) {};
            \node[node black] (n3) at (0,3) {};
            \node[node black] (n4) at (1.5,3) {};
            \node[node black] (n5) at (4.1,4.8) {};
            \node[node black] (n6) at (4,4.3) {};
            \node[node black] (n7) at (7.1,2.4) {};
            \node[node black] (n8) at (6.9,1.3) {};
            \node[node black] (n9) at (7,3,3) {};
            \node[node black] (n10) at (6,2.3) {};
            \node[node black] (n11) at (5,0) {};
            \node[node black] (n11) at (3,2.3) {};
        \end{tikzpicture}
        }
    \end{figure}

    \subsection*{Ansatz 1: Naiv}
    Man betrachtet $P_1$ und berechnet die Distanzen zu $P_2, P_3, \dots, P_n$,
    danach betrachtet man $P_2$ und berechnet die Distanzen zu $P_3, P_4, \dots, P_n$.
    Dies wird für alle verbleibenden Punkte gemacht.
    Es ergibt sich hieraus eine Laufzeit von

    \begin{equation*}
        \mathcal{O}\left(\sum_{i=1}^{n-1}\right) = \mathcal{O}\left( \frac{(n-1) \cdot n}{2} \right) = \mathcal{O}(n^2)
    \end{equation*}

    und den tabellarisch aufgelisteten Laufzeiten.

    \begin{table}[H]
        \centering
        \begin{tabular}{llll}
            \fett{n} & \fett{Rechnung} & & \fett{Ergebnis}\\
            \hline \\ [-2ex]
            $=100       $ & $100^2 \cdot 10^{-9}$       & $=10^{-5}$   & $\SI{10}{\us}$ \\
            $=1000      $ & $1000^2 \cdot 10^{-9}$      & $= 10^{-3}$    & \SI{1}{\ms} \\
            $=10000     $ & $10000^2 \cdot 10^{-9}$     & $= 10$         & \SI{10}{\s} \\
            $=1000000   $ & $1000000^2 \cdot 10^{-9}$   & $= 10^3$       & \SI{10}{\min} \\
            \hline
        \end{tabular}
        \caption*{1-GHz-Prozessor (1.000.000.000 Instruktionen pro Sekunde) für $\mathcal{O}(n^2)$}
    \end{table}

    \subsection*{Ansatz 2: Randomisiert (Las-Vegas)}

    Ein randomisierter Ansatz des Closest-Pair-Problems hat eine \kursiv{erwartete} Laufzeit von $\mathcal{O}(n)$
    und funktioniert folgendermaßen:\\

    Sei $P$ die Punktemenge mit $P_1, P_2, P_3, \dots, P_n$
    und sei $\delta_i$ die aktuelle Closest-Pair-Distanz.

    Für das \fett{Einfügen} eines neuen Punktes $P_{i+1}$ gilt allgemein:
    Die neue Closest-Pair-Distanz erhält man,
    wenn man die Abstände vom neuen Punkt zu allen bisherigen Punkten berechnet und überprüft,
    ob es einen noch kürzeren Abstand zweier Punkte gibt als $\delta_i$.\\

    Optimiert werden kann das Einfügen durch die folgende Überlegung:
    Da $\delta_i$ bekannt ist, kann nun ein Gitter mit einer Maschenweite (Breite der Zeilen/Spalten) von $\delta_i$
    erzeugt werden.

    \begin{figure}[H]
        \centering
        \begin{table}[H]
            \centering
            \scalebox{1.1}{%
            \begin{tabular}{l|l|l|l|l|l|l}
                & & & & $\cdot$ & &  \\ \hline
                & \cellcolor{yellow!50}&\cellcolor{yellow!50} &\cellcolor{yellow!50}$\cdot$ & & $\cdot$ &  \\ \hline
                &\cellcolor{yellow!50} & \cellcolor{orange!75}$\cdot$ &\cellcolor{yellow!50} & & $\cdot$ &  \\ \hline
                & \cellcolor{yellow!50}$\cdot$ &\cellcolor{yellow!50} &\cellcolor{yellow!50} & & &  \\ \hline
                & $\cdot$ & & & & &  \\ \hline
                & & & $\cdot$ & & &
            \end{tabular}
            }
        \end{table}
    \end{figure}

    Beim \fett{Einfügen} eines neuen Punktes wird zuerst der neue Punkt $P_{i+1}$ im Gitter (orange) lokalisiert.
    Anschließend werden alle Punkte in den angrenzenden Zellen (gelb)
    mit dem neuen Punkt $P_{i+1}$ verglichen. Gilt

    \begin{itemize}
        \item $\delta_{i+1} = \delta_i $ : Ist die neue Closest-Pair-Distanz identisch mit der alten
        (\fett{guter Fall}), so muss nichts weiter getan werden
        und es ergibt sich eine Laufzeit von $\mathcal{O}(1)$.
        \item $\delta_{i+1} < \delta_i $ : Ist die neue Closest-Pair-Distanz
        kleiner als die alte (\fett{schlechter Fall}),
        so muss das Gitter mit der Maschenweite $\delta_{i+1}$ neu aufgebaut werden.
        Im schlechtesten Fall ergibt sich somit eine Laufzeit von $\mathcal{O}(n^2)$.
    \end{itemize}

    Da es auch Fälle geben kann, in denen jeder neu eingefügte Punkt gleichzeitig auch ein neues Closest-Pair bildet,
    das Gitter also bei jedem Einfügeschritt neu aufgebaut werden muss (Liste, sortiert nach größtem Abstand zueinander),
    werden die Punkte in \kursiv{zufälliger Reihenfolge} eingefügt.
    So bleibt eine Wahrscheinlichkeit von $\frac{2}{i+1}$, dass der nächste Punkt ein Closest-Pair-Punkt ist.
    Die erwarteten Kosten des Einfügens \fett{pro Punkt} sind

    \begin{equation*}
        \leq \quad \underbrace{\frac{2}{i+1} \cdot \mathcal{O}(i)}_{\text{schlechter Fall}} +
        \underbrace{\mathcal{O}(1)}_{\substack{\text{guter} \\ \text{Fall}}}
        \quad = \quad \mathcal{O}(1) + \mathcal{O}(1)
        \quad = \quad \mathcal{O}(1)
    \end{equation*}

    Der Erwartungswert für das Einfügen ergibt sich zu

    \begin{align*}
        E\left[ \sum^{n}_{i=1}(\text{Kosten für Einfügen von }P_i)\right]
        &= \sum^{n}_{i=1}E[\text{Kosten für Einfügen von }P_i] \\\nonumber
        &= \sum^{n}_{i=1} \mathcal{O}(1) \quad = \quad \mathcal{O}(n)
    \end{align*}

    \begin{satz}
        Die Wahrscheinlichkeit, beim Einfügen eines neuen Punktes $P_{i+1}$ das Gitter neu aufbauen zu müssen,
        ist $< \frac{2}{i+1}$.
    \end{satz}
    \begin{proof}
        Das Gitter muss genau dann neu aufgebaut werden, wenn der neue Punkt $P_{i+1}$
        einer der beiden Punkte ist, welche das Closest-Pair in der Menge der ersten $i+1$ Punkte bestimmen.
        Jeder der ersten $i+1$ Punkte ist mit gleicher Wahrscheinlichkeit der $P_{i+1}$.
        Falls das Closest-Pair eindeutig ist, gilt
        \begin{equation*}
            \text{Pr}(\text{Gitter muss neu aufgebaut werden}) = \frac{2}{i}
        \end{equation*}

        \fett{Wichtig:} Wenn der Algorithmus länger braucht, hat das nichts mit der Eingabe zu tun.
        Der randomisierte Closest-Pair-Algorithmus berechnet \fett{immer} ein korrektes Resultat.
    \end{proof}

    \subsection*{Ansatz 3: Deterministisch}
    \begin{satz}
        Deterministisch Closest-Pair ist $\in \Omega(n \cdot \log(n))$.
    \end{satz}

    \begin{table}[!ht]
        \centering
        \begin{tabular}{llll}
            \fett{n} & \fett{Rechnung} & \fett{Ergebnis}\\
            \hline \\ [-2ex]
            $=1000000   $ & $10^6 \cdot 6 \cdot  10^{-9}$   & 6 ms \\
            \hline
        \end{tabular}
        \caption*{1-GHz-Prozessor für $\mathcal{O}(n \cdot \log(n))$}
    \end{table}

    \begin{proof}
        Man weiß, dass Elementuniqueness (gegeben $n$ Zahlen $\rightarrow$ man prüft, ob eine Zahl doppelt vorkommt)
        $\Omega(n \cdot \log(n))$ braucht.

        Wenn nun Closest-Pair vergleichsbasiert besser als $o(n \cdot \log(n))$ gelöst werden könnte,
        so könnte man auch Elementuniqueness in dieser Zeit lösen.
        Das gilt jedoch nur in einem anderen Rechenmodell (Randomisierung und Abrundung).
    \end{proof}

    \section*{Anhang}
    \label{sec:anhang}

    \subsubsection*{Zufallsvariable und Erwartungswert}
    \label{sec:zufallsvariableUndErwartungswert}
    Sei $X$ die Zufallsvariable \kursiv{Augenzahl beim Wurf} mit einem normalen Würfel.
    Der Erwartungswert berechnet sich zu

    \begin{align*}
        E[X] & = \sum \text{Ereignis} \cdot \text{Pr}(\text{Ereignis}) \\
        & = \frac{1}{6} \cdot 1 + \frac{1}{6} \cdot 2 + \frac{1}{6} \cdot 3 +
        \frac{1}{6} \cdot 4 + \frac{1}{6} \cdot 5 + \frac{1}{6} \cdot 6 \\
        & = 3,5
    \end{align*}

\end{document}